{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPmDKk6J3rgYsadROEify9n",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KESAVE8604-droid/kesaverdhen-hybrid-movie-recommender/blob/main/notebooks/Phase4_HybridFusion.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Phase 4 â€” Hybrid Fusion Layer**\n",
        "\n",
        "ğŸŒ Goal\n",
        "\n",
        "To combine the predictions of your Collaborative Filtering (CF) and Content-Based models into a single hybrid score for improved recommendation accuracy.\n",
        "\n",
        "ğŸ§© Approach 1: Weighted Average Fusion\n",
        "\n",
        "Weâ€™ll implement the weighted hybrid equation:\n",
        "\n",
        "HybridScore\n",
        "=\n",
        "ğ›¼\n",
        "Ã—\n",
        "ğ¶\n",
        "ğ¹\n",
        "_\n",
        "ğ‘†\n",
        "ğ‘\n",
        "ğ‘œ\n",
        "ğ‘Ÿ\n",
        "ğ‘’\n",
        "+\n",
        "(\n",
        "1\n",
        "âˆ’\n",
        "ğ›¼\n",
        ")\n",
        "Ã—\n",
        "ğ¶\n",
        "ğ‘œ\n",
        "ğ‘›\n",
        "ğ‘¡\n",
        "ğ‘’\n",
        "ğ‘›\n",
        "ğ‘¡\n",
        "_\n",
        "ğ‘†\n",
        "ğ‘\n",
        "ğ‘œ\n",
        "ğ‘Ÿ\n",
        "ğ‘’\n",
        "HybridScore=Î±Ã—CF_Score+(1âˆ’Î±)Ã—Content_Score\n",
        "\n",
        "Where:\n",
        "\n",
        "CF_Score â†’ Predicted rating from the collaborative model\n",
        "\n",
        "Content_Score â†’ Similarity-based score from the TF-IDF model\n",
        "\n",
        "Î± (alpha) â†’ Tunable weight (default: 0.7"
      ],
      "metadata": {
        "id": "GvuHFzcvbdV3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Step 1 â€” Import Dependencies & Load Models\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import joblib\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n"
      ],
      "metadata": {
        "id": "LSEfIIwqbgi6"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install scikit-surprise --quiet\n"
      ],
      "metadata": {
        "id": "rEdlU__7cDQQ"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install numpy==1.26.4 --force-reinstall --quiet\n"
      ],
      "metadata": {
        "id": "SJSobfcecjdM",
        "outputId": "86d4381a-5788-4d3e-d73b-b2f395cc85f4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "pytensor 2.35.1 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "jaxlib 0.7.2 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "jax 0.7.2 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "import pandas as pd\n",
        "\n",
        "# Load your saved models\n",
        "tfidf = joblib.load(\"/content/drive/MyDrive/MovieRecommender/tfidf_vectorizer.pkl\")\n",
        "tfidf_matrix = joblib.load(\"/content/drive/MyDrive/MovieRecommender/tfidf_matrix.pkl\")\n",
        "cosine_sim = joblib.load(\"/content/drive/MyDrive/MovieRecommender/cosine_similarity.pkl\")\n",
        "cf_model = joblib.load(\"/content/drive/MyDrive/MovieRecommender/collab_model.pkl\")\n",
        "\n",
        "movies_df = pd.read_csv(\"/content/drive/MyDrive/MovieRecommender/movielens_cleaned.csv\")\n",
        "\n",
        "print(\"âœ… All models and data loaded successfully!\")\n"
      ],
      "metadata": {
        "id": "EAjc1fVobuS6",
        "outputId": "20b04d80-5f65-4994-c8cb-1eb3f0394d83",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… All models and data loaded successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#  Verify Model Functionality\n",
        "from surprise import SVD\n",
        "\n",
        "# Try a test prediction\n",
        "prediction = cf_model.predict(1, 10)  # Predict rating for user 1, movie 10\n",
        "print(f\"Predicted rating for user 1 on movie 10: {prediction.est:.2f}\")\n"
      ],
      "metadata": {
        "id": "TC7ksnE_dnq2",
        "outputId": "b7737422-6518-468d-a996-49bac04f06ab",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted rating for user 1 on movie 10: 3.65\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Step 2 â€” Define Helper Functions\n",
        "#(a) Get Content-Based Similarity Scores\n",
        "indices = pd.Series(movies_df.index, index=movies_df['Clean_Title'].str.lower()).drop_duplicates()\n",
        "\n",
        "def get_content_score(movie_title, top_n=10):\n",
        "    movie_title = movie_title.lower()\n",
        "    if movie_title not in indices:\n",
        "        print(\"âŒ Movie not found in dataset.\")\n",
        "        return []\n",
        "\n",
        "    idx = indices[movie_title]\n",
        "    sim_scores = list(enumerate(cosine_sim[idx]))\n",
        "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
        "    top_indices = [i[0] for i in sim_scores[1:top_n+1]]\n",
        "\n",
        "    return movies_df.iloc[top_indices][['MovieID', 'Clean_Title', 'Genres']]\n",
        "\n",
        "#(b) Get Collaborative Filtering Predictions\n",
        "def get_cf_score(user_id, movie_id):\n",
        "    try:\n",
        "        prediction = cf_model.predict(user_id, movie_id)\n",
        "        return prediction.est\n",
        "    except:\n",
        "        return np.nan\n"
      ],
      "metadata": {
        "id": "Yf15_F99d6j9"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Step 3 â€” Hybrid Recommender Function\n",
        "def hybrid_recommend(user_id, liked_movie, alpha=0.7, top_n=10):\n",
        "    liked_movie = liked_movie.lower()\n",
        "\n",
        "    if liked_movie not in indices:\n",
        "        print(\"âŒ Movie not found in content model.\")\n",
        "        return None\n",
        "\n",
        "    # Step 1: Get top similar movies (content)\n",
        "    similar_movies = get_content_score(liked_movie, top_n=50)\n",
        "    if similar_movies.empty:\n",
        "        print(\"âŒ No similar movies found.\")\n",
        "        return None\n",
        "\n",
        "    hybrid_scores = []\n",
        "    base_idx = indices[liked_movie]\n",
        "\n",
        "    # Step 2: Combine CF and content scores\n",
        "    for _, row in similar_movies.iterrows():\n",
        "        movie_id = row['MovieID']\n",
        "        cf_score = get_cf_score(user_id, movie_id)\n",
        "        content_score = cosine_sim[base_idx][indices[row['Clean_Title'].lower()]]\n",
        "\n",
        "        # Weighted combination\n",
        "        hybrid_score = alpha * cf_score + (1 - alpha) * content_score * 5  # normalize to 5-scale\n",
        "        hybrid_scores.append((row['Clean_Title'], row['Genres'], hybrid_score))\n",
        "\n",
        "    # Step 3: Sort final recommendations\n",
        "    hybrid_df = pd.DataFrame(hybrid_scores, columns=['Movie', 'Genres', 'HybridScore'])\n",
        "    hybrid_df = hybrid_df.sort_values(by='HybridScore', ascending=False).head(top_n).reset_index(drop=True)\n",
        "\n",
        "    return hybrid_df\n"
      ],
      "metadata": {
        "id": "Rn04MDQ0eJoK"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hybrid_results = hybrid_recommend(user_id=1, liked_movie=\"Toy Story\", alpha=0.7, top_n=10)\n",
        "display(hybrid_results)\n"
      ],
      "metadata": {
        "id": "CzJwWZl4lfe6",
        "outputId": "1542884a-3f2c-4476-e924-ebb224e88305",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 280
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'cf_model' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-910651675.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhybrid_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhybrid_recommend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mliked_movie\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Toy Story\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop_n\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhybrid_results\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-3012241769.py\u001b[0m in \u001b[0;36mhybrid_recommend\u001b[0;34m(user_id, liked_movie, alpha, top_n)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mcf_predictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mmovie_id\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmovies_only\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'MovieID'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0mcf_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcf_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmovie_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0mcf_predictions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcf_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'cf_model' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install numpy==1.26.4\n",
        "!pip install scikit-surprise --no-cache-dir --force-reinstall\n"
      ],
      "metadata": {
        "id": "YY1ZYXQjmVZF",
        "outputId": "aa7893fb-cf7b-4fef-a1ac-d12f1d00261a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 999
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy==1.26.4 in /usr/local/lib/python3.12/dist-packages (1.26.4)\n",
            "Collecting scikit-surprise\n",
            "  Downloading scikit_surprise-1.1.4.tar.gz (154 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m154.4/154.4 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting joblib>=1.2.0 (from scikit-surprise)\n",
            "  Downloading joblib-1.5.2-py3-none-any.whl.metadata (5.6 kB)\n",
            "Collecting numpy>=1.19.5 (from scikit-surprise)\n",
            "  Downloading numpy-2.3.4-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (62 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m62.1/62.1 kB\u001b[0m \u001b[31m294.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting scipy>=1.6.0 (from scikit-surprise)\n",
            "  Downloading scipy-1.16.3-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (62 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m62.0/62.0 kB\u001b[0m \u001b[31m308.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading joblib-1.5.2-py3-none-any.whl (308 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m308.4/308.4 kB\u001b[0m \u001b[31m37.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-2.3.4-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (16.6 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m16.6/16.6 MB\u001b[0m \u001b[31m228.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading scipy-1.16.3-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (35.7 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m35.7/35.7 MB\u001b[0m \u001b[31m311.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: scikit-surprise\n",
            "  Building wheel for scikit-surprise (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for scikit-surprise: filename=scikit_surprise-1.1.4-cp312-cp312-linux_x86_64.whl size=2611202 sha256=82972617f48424a561084ee06808cb8f44f2fcb44413f6a5ab2a9b7aa54f2ae6\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-12z400wz/wheels/75/fa/bc/739bc2cb1fbaab6061854e6cfbb81a0ae52c92a502a7fa454b\n",
            "Successfully built scikit-surprise\n",
            "Installing collected packages: numpy, joblib, scipy, scikit-surprise\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.26.4\n",
            "    Uninstalling numpy-1.26.4:\n",
            "      Successfully uninstalled numpy-1.26.4\n",
            "  Attempting uninstall: joblib\n",
            "    Found existing installation: joblib 1.5.2\n",
            "    Uninstalling joblib-1.5.2:\n",
            "      Successfully uninstalled joblib-1.5.2\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.16.3\n",
            "    Uninstalling scipy-1.16.3:\n",
            "      Successfully uninstalled scipy-1.16.3\n",
            "  Attempting uninstall: scikit-surprise\n",
            "    Found existing installation: scikit-surprise 1.1.4\n",
            "    Uninstalling scikit-surprise-1.1.4:\n",
            "      Successfully uninstalled scikit-surprise-1.1.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 2.3.4 which is incompatible.\n",
            "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 2.3.4 which is incompatible.\n",
            "tensorflow 2.19.0 requires numpy<2.2.0,>=1.26.0, but you have numpy 2.3.4 which is incompatible.\n",
            "opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 2.3.4 which is incompatible.\n",
            "numba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.3.4 which is incompatible.\n",
            "cupy-cuda12x 13.3.0 requires numpy<2.3,>=1.22, but you have numpy 2.3.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed joblib-1.5.2 numpy-2.3.4 scikit-surprise-1.1.4 scipy-1.16.3\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "joblib",
                  "numpy",
                  "scipy"
                ]
              },
              "id": "6bfeb0ffeb674677ba14616d3cea73c5"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "\n",
        "# Mount Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Load all models\n",
        "print(\"ğŸ”„ Loading trained models...\")\n",
        "tfidf = joblib.load(\"/content/drive/MyDrive/MovieRecommender/tfidf_vectorizer.pkl\")\n",
        "tfidf_matrix = joblib.load(\"/content/drive/MyDrive/MovieRecommender/tfidf_matrix.pkl\")\n",
        "cosine_sim = joblib.load(\"/content/drive/MyDrive/MovieRecommender/cosine_similarity.pkl\")\n",
        "cf_model = joblib.load(\"/content/drive/MyDrive/MovieRecommender/collab_model.pkl\")  # <== This defines cf_model âœ…\n",
        "\n",
        "# Load your cleaned movie dataset\n",
        "movies_df = pd.read_csv(\"/content/drive/MyDrive/MovieRecommender/movielens_cleaned.csv\")\n",
        "\n",
        "# Get unique movie info\n",
        "movies_only = movies_df[['MovieID', 'Clean_Title', 'Genres', 'Year']].drop_duplicates().reset_index(drop=True)\n",
        "\n",
        "print(\"âœ… All models and data loaded successfully!\")\n"
      ],
      "metadata": {
        "id": "kbBvdKz7mapE",
        "outputId": "125cd080-a68c-4cb9-a1b3-19104efeed63",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "ğŸ”„ Loading trained models...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2432554761.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mtfidf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjoblib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/drive/MyDrive/MovieRecommender/tfidf_vectorizer.pkl\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mtfidf_matrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjoblib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/drive/MyDrive/MovieRecommender/tfidf_matrix.pkl\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mcosine_sim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjoblib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/drive/MyDrive/MovieRecommender/cosine_similarity.pkl\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0mcf_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjoblib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/drive/MyDrive/MovieRecommender/collab_model.pkl\"\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# <== This defines cf_model âœ…\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/joblib/numpy_pickle.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(filename, mmap_mode, ensure_native_byte_order)\u001b[0m\n\u001b[1;32m    747\u001b[0m                 \u001b[0;31m# it has been written with. Other arrays are coerced to the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    748\u001b[0m                 \u001b[0;31m# native endianness of the host system.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 749\u001b[0;31m                 obj = _unpickle(\n\u001b[0m\u001b[1;32m    750\u001b[0m                     \u001b[0mfobj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    751\u001b[0m                     \u001b[0mensure_native_byte_order\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mensure_native_byte_order\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/joblib/numpy_pickle.py\u001b[0m in \u001b[0;36m_unpickle\u001b[0;34m(fobj, ensure_native_byte_order, filename, mmap_mode)\u001b[0m\n\u001b[1;32m    624\u001b[0m     \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    625\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 626\u001b[0;31m         \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    627\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0munpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat_mode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m             warnings.warn(\n",
            "\u001b[0;32m/usr/lib/python3.12/pickle.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1254\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mEOFError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1255\u001b[0m                 \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbytes_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1256\u001b[0;31m                 \u001b[0mdispatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1257\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0m_Stop\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mstopinst\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1258\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mstopinst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/joblib/numpy_pickle.py\u001b[0m in \u001b[0;36mload_build\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    460\u001b[0m                 \u001b[0m_array_payload\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray_wrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 462\u001b[0;31m                 \u001b[0m_array_payload\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray_wrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_native_byte_order\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    463\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    464\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_array_payload\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/joblib/numpy_pickle.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, unpickler, ensure_native_byte_order)\u001b[0m\n\u001b[1;32m    282\u001b[0m             \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munpickler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 284\u001b[0;31m             \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munpickler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_native_byte_order\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    285\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m         \u001b[0;31m# Manage array subclass case\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/joblib/numpy_pickle.py\u001b[0m in \u001b[0;36mread_array\u001b[0;34m(self, unpickler, ensure_native_byte_order)\u001b[0m\n\u001b[1;32m    195\u001b[0m                 \u001b[0mread_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_read_count\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m                 \u001b[0mread_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mread_count\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitemsize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 197\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_read_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfile_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mread_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"array data\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    198\u001b[0m                 array[i : i + read_count] = unpickler.np.frombuffer(\n\u001b[1;32m    199\u001b[0m                     \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mread_count\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/joblib/numpy_pickle_utils.py\u001b[0m in \u001b[0;36m_read_bytes\u001b[0;34m(fp, size, error_template)\u001b[0m\n\u001b[1;32m    264\u001b[0m         \u001b[0;31m# done about that.  note that regular files can't be non-blocking\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 266\u001b[0;31m             \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    267\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"movies_df shape:\", movies_df.shape)\n",
        "print(\"cosine_sim shape:\", cosine_sim.shape)\n"
      ],
      "metadata": {
        "id": "_I_lZm0JlqVx",
        "outputId": "4c6e2647-67c4-4e86-ac66-30986eb0393b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "movies_df shape: (1000209, 12)\n",
            "cosine_sim shape: (3706, 3706)\n"
          ]
        }
      ]
    }
  ]
}